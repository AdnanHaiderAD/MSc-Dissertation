Steps Taken So far:

Splitting of data sets:
For Training : The entire training data is used
--To contain the computational complexitiy, I am usig samples from production 'a'


For the training set : 
To reduce the average mean time , I am using half of the training data set:
I have chosen:
 225 samples from the boy category
 234 samples from the girl category
 495 samples from the men category
 513 samples from the women category

Note : the size of the training set is half of the original training set but contains examples of all classes [1-9]  

For the  test set : Due to the high computational complexity, I  am using only 1/3 of the test set
I have chosen 
162 random samples from boys
162 random samples from girls
326 random samples from men
326 random samples from women


Steps:

Feature selection and data preprocessing


Feature selection:
Investigating linear and non linear features:

Choices: 1) The amplitude values
	 2) MFCC features
	 3) MFCC-whitened
	 4) Local +Global features
	 5)Local +Global whitened Features

Baseline DTW:
standard DTW with o constraints  augmented with euclidean metric

Baseline model:
Using DTW + amplitude (empirical observed values)
Prob: The time taken to compare a single test point with the entire training set takes 36000s (over 10 hours)
To speed up the process, I performed the following steps:

The size of the DTW cost matrix is govererned by the length of the vectors. Subsampling the sequence results in a smaller sequence that leads to smaller DTW matrix and hence lesser computational time.
Problem: Subsampling lead to loss of information (both local+global). To tackle the problem I created a filter which infacts improves the quality of the utternace signal. The filter first removes regions of silence from the utterance and down subsamples the remaining signal by half.
Observations: 1) The extracted signal is much more clearer to understand
	      2) This procedue seems to have diminished the effect of accents.

However the time taken to compare a single test point with the entire training set  now takes 16000 (over 4 hours)
Steps taken to speed up DTW:

1) adding a adaptive warping window of size      max(0.1* longestsignal, abs (length (signal 1)-length(signal2))) 
Smaller warping windows speed up the DTW calculations simply because there is less area of the warping matrix to be searched but at the expense of accuracy!
Potential containment:

Test
Two classes:"8" and "9"
Four samples : 2 samples of class "8" and 2 samples of class "9".
samples for "8" : 1 sample from boy category and 1 sample from men category
samples for "9" : 1 sample from boy category and 1 sample from men category

Tests conducted
let n be size of one utterance and m be the size of the second utternace

using window abs (n-m):
		comparing 8 and 8:
		distortion=0.049
		Time= 7.5s

		comparing 8 and 9 :
		distortion = 2.89
		Time =53s

		comparing 9 and 8 :
		distortion = 0.163
		Time =24s
		
		comparing  9 and 9
		distortion = 1.089
		Time = 68.5s

confusion matrix :
	    T F
        T   1 1       
        F   1 1

boy  40.0000
         0
         0
   31.5789
         0
         0
   47.0588
         0
         0

girl
 35.7143
         0
         0
   16.6667
         0
         0
   56.2500
         0
         0


men
30.7692
         0
         0
   28.0000
    5.8824
         0
   60.0000
         0
         0


women 
 34.2857
         0
    3.7037
   32.1429
         0
    4.3478
   47.3684
         0
         0





